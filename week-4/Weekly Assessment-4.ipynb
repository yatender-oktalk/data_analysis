{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9ab2d1",
   "metadata": {},
   "source": [
    "# Weekly Assessment-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77994a7",
   "metadata": {},
   "source": [
    "## Step 1: Import and Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfcf4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2_contingency\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "\n",
    "# Suppress warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Data Preparation and Loading\n",
    "def load_and_prepare_data(filepath):\n",
    "    \"\"\"\n",
    "    Load the dataset and prepare it for analysis\n",
    "    \"\"\"\n",
    "    # Determine file extension and use appropriate reading method\n",
    "    # file_ext = os.path.splitext(filepath)[1].lower()\n",
    "    \n",
    "    # if file_ext == '.xlsx':\n",
    "    #     df = pd.read_excel(filepath)\n",
    "    # elif file_ext == '.csv':\n",
    "    df = pd.read_csv(filepath)\n",
    "    # else:\n",
    "    #     raise ValueError(f\"Unsupported file type: {file_ext}\")\n",
    "    \n",
    "    # Convert Month to categorical if needed\n",
    "    if 'Month' in df.columns:\n",
    "        df['Month'] = pd.Categorical(df['Month'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c2be9",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfd7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the data for cluster analysis and PCA\n",
    "    \"\"\"\n",
    "    # Select numeric columns for analysis\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove specific columns if needed\n",
    "    exclude_cols = ['SexID'] if 'SexID' in numeric_columns else []\n",
    "    numeric_columns = [col for col in numeric_columns if col not in exclude_cols]\n",
    "    \n",
    "    if len(numeric_columns) < 2:\n",
    "        raise ValueError(\"Need at least 2 numeric columns for analysis\")\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = df[numeric_columns].to_numpy()  # Convert to numpy array explicitly\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, numeric_columns, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d149669",
   "metadata": {},
   "source": [
    "## Step 3: Perform K-means Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbab24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(X_scaled, df, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering and analyze alignment with personality groups\n",
    "    \"\"\"\n",
    "    # Ensure X_scaled is numpy array\n",
    "    if not isinstance(X_scaled, np.ndarray):\n",
    "        X_scaled = np.array(X_scaled)\n",
    "    \n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Encode original personality groups\n",
    "    le = LabelEncoder()\n",
    "    true_labels = le.fit_transform(df['Personality'])\n",
    "    \n",
    "    # Calculate alignment metrics\n",
    "    alignment_metrics = {}\n",
    "    for i in range(n_clusters):\n",
    "        cluster_mask = (cluster_labels == i)\n",
    "        cluster_personalities = df.loc[cluster_mask, 'Personality']\n",
    "        personality_counts = cluster_personalities.value_counts(normalize=True)\n",
    "        alignment_metrics[f'Cluster {i}'] = personality_counts\n",
    "    \n",
    "    # Perform statistical test\n",
    "    contingency_table = pd.crosstab(df['Personality'], cluster_labels)\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    return cluster_labels, alignment_metrics, chi2, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1b819",
   "metadata": {},
   "source": [
    "## Step 4: Perform PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9e0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(X_scaled):\n",
    "    \"\"\"\n",
    "    Perform Principal Component Analysis\n",
    "    \"\"\"\n",
    "    # Ensure X_scaled is numpy array\n",
    "    if not isinstance(X_scaled, np.ndarray):\n",
    "        X_scaled = np.array(X_scaled)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA()\n",
    "    pca_results = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Calculate explained variance\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    return pca, pca_results, explained_variance, cumulative_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea0742",
   "metadata": {},
   "source": [
    "## Step 5: Create Cluster Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec08897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_plot(X_scaled, cluster_labels, df, numeric_columns):\n",
    "    \"\"\"\n",
    "    Create detailed cluster visualization\n",
    "    \"\"\"\n",
    "    # Convert to numpy array if needed\n",
    "    X_scaled = np.array(X_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Use first two components for plotting\n",
    "    X_plot = X_scaled[:, :2]\n",
    "    \n",
    "    # First subplot - Clustering\n",
    "    plt.subplot(1, 2, 1)\n",
    "    scatter = plt.scatter(X_plot[:, 0], X_plot[:, 1], \n",
    "                         c=cluster_labels, \n",
    "                         cmap='viridis', \n",
    "                         alpha=0.7)\n",
    "    plt.title('K-Means Clustering Visualization', fontsize=12)\n",
    "    plt.xlabel(f'{numeric_columns[0]} (Standardized)', fontsize=10)\n",
    "    plt.ylabel(f'{numeric_columns[1]} (Standardized)', fontsize=10)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    \n",
    "    # Second subplot - Original Personality Groups\n",
    "    plt.subplot(1, 2, 2)\n",
    "    personality_encoder = LabelEncoder()\n",
    "    personality_codes = personality_encoder.fit_transform(df['Personality'])\n",
    "    scatter = plt.scatter(X_plot[:, 0], X_plot[:, 1], \n",
    "                         c=personality_codes, \n",
    "                         cmap='Set1', \n",
    "                         alpha=0.7)\n",
    "    plt.title('Original Personality Groups', fontsize=12)\n",
    "    plt.xlabel(f'{numeric_columns[0]} (Standardized)', fontsize=10)\n",
    "    plt.ylabel(f'{numeric_columns[1]} (Standardized)', fontsize=10)\n",
    "    plt.colorbar(scatter, \n",
    "                ticks=range(len(personality_encoder.classes_)),\n",
    "                label='Personality')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = 'cluster_plot.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return plot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef74241",
   "metadata": {},
   "source": [
    "## Step 6: Create PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c453e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_plot(pca_results, explained_variance, cluster_labels):\n",
    "    \"\"\"\n",
    "    Create PCA visualization\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # First two principal components scatter plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    scatter = plt.scatter(pca_results[:, 0], pca_results[:, 1], \n",
    "                         c=cluster_labels, \n",
    "                         cmap='viridis', \n",
    "                         alpha=0.7)\n",
    "    plt.title('PCA: First Two Principal Components', fontsize=12)\n",
    "    plt.xlabel('First Principal Component (PC1)', fontsize=10)\n",
    "    plt.ylabel('Second Principal Component (PC2)', fontsize=10)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    \n",
    "    # Explained variance bar plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(1, len(explained_variance) + 1), \n",
    "            explained_variance * 100, \n",
    "            alpha=0.7)\n",
    "    plt.title('Variance Explained by Principal Components', fontsize=12)\n",
    "    plt.xlabel('Principal Components', fontsize=10)\n",
    "    plt.ylabel('Explained Variance (%)', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = 'pca_plot.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return plot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846c628",
   "metadata": {},
   "source": [
    "## Step 7: Generate Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee88b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing data...\n",
      "Data shape: (67, 11)\n",
      "Numeric columns: ['Weight', 'WingL', 'TarsusL', 'CORT1', 'CORT2', 'CORT3', 'Exploration', 'Neophobia', 'Neophilia', 'Aggression', 'Boldness']\n",
      "Performing clustering...\n",
      "Performing PCA...\n",
      "Creating visualizations...\n",
      "Creating PDF report...\n",
      "PDF report saved to Cardinal_Personalities_Analysis.pdf\n",
      "Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def create_comprehensive_pdf(df, X_scaled, cluster_labels, alignment_metrics, chi2, p_value, \n",
    "                           pca_results, explained_variance, cumulative_variance, \n",
    "                           numeric_columns):\n",
    "    \"\"\"\n",
    "    Create a comprehensive PDF report\n",
    "    \"\"\"\n",
    "    # Register a default font\n",
    "    pdfmetrics.registerFont(TTFont('Arial', 'Arial.ttf'))\n",
    "    \n",
    "    pdf_path = 'Cardinal_Personalities_Analysis.pdf'\n",
    "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "    width, height = A4\n",
    "    \n",
    "    # Title\n",
    "    c.setFont('Arial', 16)\n",
    "    c.drawString(inch, height - inch, \"Cardinal Personalities Analysis Report\")\n",
    "    \n",
    "    # Cluster Plot\n",
    "    cluster_plot_path = create_cluster_plot(X_scaled, cluster_labels, df, numeric_columns)\n",
    "    c.drawImage(cluster_plot_path, inch, height/2, width-2*inch, height/3)\n",
    "    \n",
    "    # Plot descriptions\n",
    "    c.setFont('Arial', 10)\n",
    "    c.drawString(inch, height/2 - 20, \"Figure 1: Cluster Analysis Results\")\n",
    "    c.drawString(inch, height/2 - 40, \"Left: K-means clustering visualization  Right: Original personality groups\")\n",
    "    \n",
    "    # PCA Plot on new page\n",
    "    c.showPage()\n",
    "    pca_plot_path = create_pca_plot(pca_results, explained_variance, cluster_labels)\n",
    "    c.drawImage(pca_plot_path, inch, height/2, width-2*inch, height/3)\n",
    "    \n",
    "    c.drawString(inch, height/2 - 20, \"Figure 2: Principal Component Analysis\")\n",
    "    c.drawString(inch, height/2 - 40, \"Left: First two principal components  Right: Explained variance by components\")\n",
    "    \n",
    "    # Results and interpretation on new page\n",
    "    c.showPage()\n",
    "    c.setFont('Arial', 14)\n",
    "    c.drawString(inch, height - inch, \"Analysis Results\")\n",
    "    \n",
    "    c.setFont('Arial', 10)\n",
    "    y_position = height - 2*inch\n",
    "    \n",
    "    # Write clustering results\n",
    "    c.drawString(inch, y_position, \"Clustering Results:\")\n",
    "    y_position -= 20\n",
    "    \n",
    "    for cluster, personalities in alignment_metrics.items():\n",
    "        c.drawString(inch + 20, y_position, f\"{cluster}:\")\n",
    "        y_position -= 15\n",
    "        for personality, proportion in personalities.items():\n",
    "            c.drawString(inch + 40, y_position, f\"{personality}: {proportion:.2%}\")\n",
    "            y_position -= 15\n",
    "        y_position -= 10\n",
    "    \n",
    "    # Write statistical test results\n",
    "    c.drawString(inch, y_position, f\"Chi-square test results:\")\n",
    "    y_position -= 15\n",
    "    c.drawString(inch + 20, y_position, f\"χ² statistic: {chi2:.2f}\")\n",
    "    y_position -= 15\n",
    "    c.drawString(inch + 20, y_position, f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Write PCA results\n",
    "    y_position -= 30\n",
    "    c.drawString(inch, y_position, \"PCA Results:\")\n",
    "    y_position -= 15\n",
    "    for i, var in enumerate(explained_variance[:3], 1):\n",
    "        c.drawString(inch + 20, y_position, f\"PC{i} explained variance: {var:.2%}\")\n",
    "        y_position -= 15\n",
    "    \n",
    "    c.save()\n",
    "    print(f\"PDF report saved to {pdf_path}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        filepath = 'week-4/download-6.csv'\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(\"Loading data...\")\n",
    "        df = load_and_prepare_data(filepath)\n",
    "        \n",
    "        print(\"Preprocessing data...\")\n",
    "        X_scaled, numeric_columns, df = preprocess_data(df)\n",
    "        \n",
    "        print(f\"Data shape: {X_scaled.shape}\")\n",
    "        print(f\"Numeric columns: {numeric_columns}\")\n",
    "        \n",
    "        # Perform clustering\n",
    "        print(\"Performing clustering...\")\n",
    "        cluster_labels, alignment_metrics, chi2, p_value = perform_kmeans_clustering(X_scaled, df)\n",
    "        \n",
    "        # Perform PCA\n",
    "        print(\"Performing PCA...\")\n",
    "        pca, pca_results, explained_variance, cumulative_variance = perform_pca(X_scaled)\n",
    "        \n",
    "        # Create visualizations\n",
    "        print(\"Creating visualizations...\")\n",
    "        create_cluster_plot(X_scaled, cluster_labels, df, numeric_columns)\n",
    "        create_pca_plot(pca_results, explained_variance, cluster_labels)\n",
    "        \n",
    "        # Create PDF report\n",
    "        print(\"Creating PDF report...\")\n",
    "        create_comprehensive_pdf(df, X_scaled, cluster_labels, alignment_metrics, chi2, p_value, \n",
    "                               pca_results, explained_variance, cumulative_variance, \n",
    "                               numeric_columns)\n",
    "        \n",
    "        print(\"Analysis completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
